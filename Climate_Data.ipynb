{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy, os, re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Climate Change\n",
    "\n",
    "## Background\n",
    "Climate Change is defined as the long-term changes in Earth's climate and weather patterns and Climate is often defined as the average weather at a particular place or as the mean state and variablility of features such as temperature, precipitiation, and humidity over some extended time period. Shifts in the climate can be natural, such as changes in the sun's activity or it can be anthropogenic. The extent of the current climate change can laragly be attributed to human actvity such as the burning of fossil fuels like coal, oil, and gas. The burning of fossil fuels generates greenhouse gas which traps the sun's heat and therefore rasies the temperature. The average tempertaure of the Earth's surface is now about 1.1 C warm than it was before the indusrial revolution. Climate change means more than just warmer temperatures, it also includes, among others, intense droughts, severe fire, rising sea level, and more intense storms.\n",
    "\n",
    "## Goals\n",
    "The goal of this project is to examine the temperature and precipitation aspects of climate data to understand global and regional trends and the realtion between climate varaibles and greenhouse gas emissions. Futhermore, it aims to model potential future scenarios based on current trends over differnt time horizen.\n",
    "    \n",
    "1. Are there discerbinle trends in temperature and precipitation over the given time period, globally and across different regions/countries?\n",
    "2. Are there regions/countries that are experiencing more drastic changes compared to others?\n",
    "3. Are there any extreme weather events that show a significant increase in frequency or itensity over time\n",
    "4. Are there any discerbinle trends in temperature and precipitation that differs between developed and developing countries?\n",
    "5. Can the data be compared with greenhouse gas emissions data to assess the realtionship between emissions and climate varaibles?\n",
    "6. If the current trends shown in the data continues without any significant change, where would we be in 10/50/100 years from now?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering\n",
    "## Dataset\n",
    "The main dataset used in this project is the Global Historical Climatology Network - Daily (GHCN-Daily), Version 3 sourced from the National Oceanic and Atmospheric Administration. The dataset is available for public use , with the only limitations being that the \"*NOAA and NCEI cannot provide any warranty as to the accuracy, reliability, or completeness of furnished data. Users assume responsibility to determine the usability of these data. The user is responsible for the results of any application of this data for other than its intended purpose.*\"\n",
    "\n",
    "### Dataset Metadata\n",
    "File Size - 131 GB  <br>\n",
    "Number of Files - 125, 391\n",
    "\n",
    "#### Measurements:\n",
    "1. Precipitations (tenths of mm, PRCP)\n",
    "2. Temperature Max (tenths of degrees C, TMAX)\n",
    "3. Temperature Min (tenths of degrees C, TMIN)\n",
    "4. Temperature Average (tenths of degrees C, TAXN)\n",
    "5. Snowfall (mm, SNOW)\n",
    "6. Snow Depth (mm SNWD)\n",
    "\n",
    "### Data Range\n",
    ">Most Frequent Start Date: 1901-01-01      *(count: 1715)* <br>\n",
    ">Most Frequent End Date: 2024-02-08    *(count: 11137)*\n",
    ">\n",
    ">\n",
    ">Date Range: 1901-01-01 ~ 2023-12-31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Out Irrelevant and Empty Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_csv(input_file, columns):\n",
    "    df_in = pd.read_csv(input_file, dtype=str)\n",
    "    df_columns = df_in.columns.to_list()\n",
    "\n",
    "    valid_col = [col for col in columns if col in df_columns]\n",
    "\n",
    "    #Filter the DataFrame based on columns\n",
    "    filtered_df = df_in[valid_col]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def check_empty_columns(df):\n",
    "    #Filters out the empty columns\n",
    "    filtered_df = df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "def filter_columns():\n",
    "    #columns names in csv file\n",
    "    col = [\"TMAX\", 'TMIN', 'TAXN', 'PRCP', 'SNOW', 'SNWD', 'DATE', 'STATION']\n",
    "\n",
    "    input_loc = r'Data\\\\'\n",
    "    output_loc = r'Filtered Data'\n",
    "\n",
    "    #filter file in dir to perfect & other folder based contents\n",
    "    for item in os.listdir(input_loc):\n",
    "        df = filter_csv(input_loc+ item, col)\n",
    "        \n",
    "        filter_df = check_empty_columns(df)\n",
    "\n",
    "        filter_df.to_csv(os.path.join(output_loc, item), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Out Files Without Requisite Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_columns(df):\n",
    "    temp_col = [\"TMAX\", \"TMIN\"]\n",
    "    avgTemp_col = [\"TAXN\"]\n",
    "    other_col = [\"PRCP\", 'SNOW', 'SNWD']\n",
    "\n",
    "    df_col = df.columns.to_list()\n",
    "\n",
    "    temp_cond = all(col in df_col for col in temp_col)\n",
    "    avgTemp_cond = all(col in df_col for col in avgTemp_col)\n",
    "\n",
    "    if temp_cond or avgTemp_cond:\n",
    "        if all(col in df_col for col in other_col): return 'pt' #add to perfect data\n",
    "        else: return 'tp' #add to temp data\n",
    "    else: return 'pr' #only precipitation data\n",
    "\n",
    "def run_filter():\n",
    "    #columns names in csv file\n",
    "    col = [\"TMAX\", 'TMIN', 'TAXN', 'PRCP', 'SNOW', 'SNWD', 'DATE', 'STATION']\n",
    "\n",
    "    input_loc = r'Data\\\\'\n",
    "    output_loc = r'Filtered Data'\n",
    "\n",
    "    #filter file in dir to perfect & other folder based contents\n",
    "    for item in os.listdir(input_loc):\n",
    "        filter_df = pd.read_csv(input_loc+item, dtype=str)\n",
    "\n",
    "        key = filter_columns(filter_df)\n",
    "\n",
    "        # check the key to see which folder to put csv file in Filtered Data\n",
    "        if key == 'pt': filter_df.to_csv(os.path.join(output_loc, 'Perfect', item), index=False)\n",
    "        if key == 'tp': filter_df.to_csv(os.path.join(output_loc, 'Temperature', item), index=False)\n",
    "        if key == 'pr': filter_df.to_csv(os.path.join(output_loc, 'Precipitation', item), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering out Data Over Defined Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_keydic():\n",
    "    code_loc = r'Other\\\\ghcnd-countries.txt'\n",
    "    code_key = {}\n",
    "        \n",
    "    with open(code_loc) as f:\n",
    "        data = f.readlines()\n",
    "        \n",
    "    for line in data:\n",
    "        code, country = line.split(' ', 1)\n",
    "\n",
    "        if '[' in country:\n",
    "            country = re.sub(r'\\[[^\\]]*\\]', '', country)\n",
    "            country = re.sub(r'\\s{2,}', ' ', country)\n",
    "        country = country.strip()\n",
    "\n",
    "        code_key[code] = country\n",
    "\n",
    "    return code_key\n",
    "\n",
    "def code_to_country(txt, key):\n",
    "    code = txt[:2]\n",
    "    return key[code]\n",
    "\n",
    "def filter_threshold():\n",
    "    data_loc = r'Filtered Data\\\\Perfect'\n",
    "    output_loc = r'Filtered Data\\\\Perfect Threshold'\n",
    "    thershold_datapath = r'Other\\\\Table_Extreme_Records_Hemisphere.csv'\n",
    "    \n",
    "    #countries in each hemisphere\n",
    "    with open(r'Other\\both_hemisphere.txt') as f:\n",
    "        whole = [line.strip() for line in f.readlines()]\n",
    "    with open(r'Other\\northern_hemisphere.txt') as f:\n",
    "        nth_hs = [line.strip() for line in f.readlines()]\n",
    "    with open(r'Other\\southern_hemisphere.txt') as f:\n",
    "        sth_hs = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    #country code dic\n",
    "    countrycode_dic = code_keydic()\n",
    "    \n",
    "    #threshold dataframe\n",
    "    thres_df = pd.read_csv(thershold_datapath)\n",
    "    tempMx, tempMn, prcp = [], [], []\n",
    "    \n",
    "    for index, row in thres_df.iterrows():\n",
    "        if row['Characteristic'] == 'TMAX':\n",
    "            if row['Hemisphere'] == 'Northern': tempMx.append(row['Value'])\n",
    "            if row['Hemisphere'] == 'Southern': tempMx.append(row['Value'])\n",
    "        elif row['Characteristic'] == 'TMIN':\n",
    "            if row['Hemisphere'] == 'Northern': tempMn.append(row['Value'])\n",
    "            if row['Hemisphere'] == 'Southern': tempMn.append(row['Value'])\n",
    "        elif row['Characteristic'] == 'PRCP':\n",
    "            if row['Hemisphere'] == 'Northern': prcp.append(row['Value'])\n",
    "            if row['Hemisphere'] == 'Southern': prcp.append(row['Value'])\n",
    "    \n",
    "    for item in os.listdir(data_loc):\n",
    "        code = item[:2]\n",
    "        country_name = code_to_country(code, countrycode_dic)\n",
    "\n",
    "        orgi_loc = os.path.join(data_loc, item)\n",
    "        df = pd.read_csv(orgi_loc)\n",
    "        \n",
    "        # check which hemisphere the country is in\n",
    "        if country_name in whole:\n",
    "            if df['TMAX'].max()/10 > max(tempMx): continue\n",
    "            if df['TMIN'].min()/10 < min(tempMn): continue\n",
    "            if df['PRCP'].max()/10 > max(prcp): continue\n",
    "            \n",
    "            #move files after data is validated\n",
    "            new_loc = os.path.join(output_loc, item)\n",
    "            os.replace(orgi_loc, new_loc)\n",
    "\n",
    "        elif country_name in nth_hs:\n",
    "            if df['TMAX'].max()/10 > tempMx[0]: continue\n",
    "            if df['TMIN'].min()/10 < tempMn[0]: continue\n",
    "            if df['PRCP'].max()/10 > prcp[0]: continue\n",
    "\n",
    "            #move files after data is validated\n",
    "            new_loc = os.path.join(output_loc, item)\n",
    "            os.replace(orgi_loc, new_loc)\n",
    "\n",
    "        elif country_name in sth_hs:\n",
    "            if df['TMAX'].max()/10 > tempMx[1]: continue\n",
    "            if df['TMIN'].min()/10 < tempMn[1]: continue\n",
    "            if df['PRCP'].max()/10 > prcp[1]: continue\n",
    "\n",
    "            #move files after data is validated\n",
    "            new_loc = os.path.join(output_loc, item)\n",
    "            os.replace(orgi_loc, new_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_data():\n",
    "    data_loc = r'Filtered Example Data\\\\Perfect Threshold'\n",
    "    output_loc = r'Filtered Example Data\\\\Ready Data'\n",
    "\n",
    "    for item in os.listdir(data_loc):\n",
    "        orgi_loc = os.path.join(data_loc, item)\n",
    "        new_loc = os.path.join(output_loc, item)\n",
    "\n",
    "        df =  pd.read_csv(orgi_loc)\n",
    "\n",
    "        count = 0\n",
    "        for col in df.columns:\n",
    "            # nan percentage is the percentage of missing data\n",
    "            nan_percentage = (df[col].isna().sum() / len(df)) * 100\n",
    "            if nan_percentage > 50: count += 1\n",
    "\n",
    "        if count == 0:  os.replace(orgi_loc, new_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aggregation (Temporal and Spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_last_occurrence(lst):\n",
    "    occurrences = {}\n",
    "    current, first = None, None\n",
    "\n",
    "    for idx, item in enumerate(lst):\n",
    "        if item[:2] != current:\n",
    "            if current is not None: occurrences[current] = (first, idx)\n",
    "            current = item[:2]\n",
    "            first = idx\n",
    "    \n",
    "    if current is not None: occurrences[current] = (first, len(lst) - 1)\n",
    "\n",
    "    return occurrences\n",
    "\n",
    "def monthy_yearly_data():\n",
    "    data_loc = r'Filtered Data\\\\Ready Data'\n",
    "    output_loc =  r'Filtered Data\\\\Data Aggregation'\n",
    "    \n",
    "    lst_of_csv = os.listdir(data_loc)\n",
    "    lst_of_csv.sort()\n",
    "    country_code_dic = find_first_last_occurrence(lst_of_csv)\n",
    "\n",
    "    for ccode in country_code_dic.keys():\n",
    "        startIdx, endIdx = country_code_dic[ccode][0], country_code_dic[ccode][1]\n",
    "        monthly_lst, yearly_lst = [], []\n",
    "\n",
    "        for item in lst_of_csv[startIdx:endIdx]:\n",
    "            df = pd.read_csv(os.path.join(data_loc, item))\n",
    "\n",
    "            #create new year and month column from data column\n",
    "            df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "            df['Year'] = df['DATE'].dt.year\n",
    "            df['Month'] = df['DATE'].dt.month\n",
    "\n",
    "            #calculate monthly and yearly average for each column\n",
    "            col_to_include = df.columns[df.columns != 'STATION']\n",
    "            monthly_avg = df.groupby(['Year', 'Month'])[col_to_include].mean()\n",
    "            yearly_avg = df.groupby(['Year'])[col_to_include].mean()\n",
    "\n",
    "            #append the results to the lists\n",
    "            monthly_lst.append(monthly_avg)\n",
    "            yearly_lst.append(yearly_avg)\n",
    "        \n",
    "        #concatenate all dataframe from all csv files that are in list\n",
    "        country_monthly_avg = pd.concat(monthly_lst)\n",
    "        country_yearly_avg = pd.concat(yearly_lst)\n",
    "\n",
    "        #drop last two duplicate columns\n",
    "        country_monthly_avg = country_monthly_avg.iloc[:, :-3]\n",
    "        country_yearly_avg = country_yearly_avg.iloc[:, :-3]\n",
    "\n",
    "        # get the mean for every year and mean for every month\n",
    "        country_monthly_avg  = country_monthly_avg.groupby(['Year', 'Month']).mean()\n",
    "        country_yearly_avg = country_yearly_avg.groupby(['Year']).mean()\n",
    "\n",
    "        # divide value in dataframe by 10 to get accurate units\n",
    "        columns_to_divide_10 = ['TMAX', 'TMIN', 'PRCP']\n",
    "        \n",
    "        country_monthly_avg[columns_to_divide_10] = country_monthly_avg[columns_to_divide_10]/10\n",
    "        country_yearly_avg[columns_to_divide_10] = country_yearly_avg[columns_to_divide_10]/10\n",
    "\n",
    "        # round all the data besides timestamp\n",
    "        columns_to_round = ['TMAX', 'TMIN', 'PRCP', 'SNOW', 'SNWD']\n",
    "\n",
    "        country_monthly_avg[columns_to_round] = country_monthly_avg[columns_to_round].round(4)\n",
    "        country_yearly_avg[columns_to_round] = country_yearly_avg[columns_to_round].round(4)\n",
    "\n",
    "        #save to csv file\n",
    "        country_monthly_avg.to_csv(os.path.join(output_loc, f'monthly_avg_{ccode}.csv'))\n",
    "        country_yearly_avg.to_csv(os.path.join(output_loc, f'yearly_avg_{ccode}.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Feature Engineering\n",
    "\n",
    "### Trends\n",
    "Are there discerbinle trends in temperature and precipitation over the given time period, globally and across different regions/countries?\n",
    "Are there any extreme weather events that show a significant increase in frequency or itensity over time\n",
    "\n",
    "### Regional Trend Comparison\n",
    "Are there regions/countries that are experiencing more drastic changes compared to others?\n",
    "Are there any discerbinle trends in temperature and precipitation that differs between developed and developing countries?\n",
    "\n",
    "### Data Comparison\n",
    "Can the data be compared with greenhouse gas emissions data to assess the realtionship between emissions and climate varaibles?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development\n",
    "\n",
    "If the current trends shown in the data continues without any significant change, where would we be in 10/50/100 years from now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
